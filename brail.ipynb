{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "472888cb-abc7-4cd2-aaa3-58275f6d3ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.43 ðŸš€ Python-3.10.12 torch-2.1.1+cu121 CPU\n",
      "Model summary (fused): 218 layers, 25891088 parameters, 0 gradients, 79.7 GFLOPs\n",
      "\n",
      "0: 640x640 2 001111s, 2 010100s, 2 010110s, 1 011100, 1 011110, 2 100000s, 4 100010s, 2 100100s, 4 100110s, 1 101001, 1 101010, 1 101011, 1 101100, 1 101101, 1 101110, 1 101111, 3 110000s, 3 110010s, 2 110100s, 2 110110s, 2 111000s, 1 111001, 2 111010s, 1 111100, 1 111110, 404.5ms\n",
      "Speed: 0.7ms preprocess, 404.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100000', '110000', '100100', '110100', '100110', '100010', '100110', '110100', '110110', '110010', '010100', '100010', '110010', '111000', '111000', '101100', '101110', '101010', '111100', '111110', '111010', '011100', '011110', '101001', '001111', '111010', '101101', '101111', '101011', '001111', '111001', '110010', '010110', '100000', '110000', '100100', '100110', '100010', '100110', '110110', '010110', '010100', '100010', '110000']\n"
     ]
    }
   ],
   "source": [
    "## brail letter #\n",
    "import time\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "from ultralyticsplus import YOLO, render_result\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def convert_to_braille_unicode(str_input: str, path: str = \"./braille-map.json\") -> str:\n",
    "    with open(path, \"r\") as fl:\n",
    "        data = json.load(fl)\n",
    "\n",
    "    if str_input in data.keys():\n",
    "        str_output = data[str_input]\n",
    "    return str_output\n",
    "\n",
    "\n",
    "def parse_xywh_and_class(boxes: torch.Tensor) -> list:\n",
    "    \"\"\"\n",
    "    boxes input tensor\n",
    "        boxes (torch.Tensor) or (numpy.ndarray): A tensor or numpy array containing the detection boxes,\n",
    "            with shape (num_boxes, 6).\n",
    "        orig_shape (torch.Tensor) or (numpy.ndarray): Original image size, in the format (height, width).\n",
    "\n",
    "    Properties:\n",
    "        xyxy (torch.Tensor) or (numpy.ndarray): The boxes in xyxy format.\n",
    "        conf (torch.Tensor) or (numpy.ndarray): The confidence values of the boxes.\n",
    "        cls (torch.Tensor) or (numpy.ndarray): The class values of the boxes.\n",
    "        xywh (torch.Tensor) or (numpy.ndarray): The boxes in xywh format.\n",
    "        xyxyn (torch.Tensor) or (numpy.ndarray): The boxes in xyxy format normalized by original image size.\n",
    "        xywhn (torch.Tensor) or (numpy.ndarray): The boxes in xywh format normalized by original image size.\n",
    "    \"\"\"\n",
    "\n",
    "    # copy values from troublesome \"boxes\" object to numpy array\n",
    "    new_boxes = np.zeros(boxes.shape)\n",
    "    new_boxes[:, :4] = boxes.xywh.numpy()  # first 4 channels are xywh\n",
    "    new_boxes[:, 4] = boxes.conf.numpy()  # 5th channel is confidence\n",
    "    new_boxes[:, 5] = boxes.cls.numpy()  # 6th channel is class which is last channel\n",
    "\n",
    "    # sort according to y coordinate\n",
    "    new_boxes = new_boxes[new_boxes[:, 1].argsort()]\n",
    "\n",
    "    # find threshold index to break the line\n",
    "    y_threshold = np.mean(new_boxes[:, 3]) // 2\n",
    "    boxes_diff = np.diff(new_boxes[:, 1])\n",
    "    threshold_index = np.where(boxes_diff > y_threshold)[0]\n",
    "\n",
    "    # cluster according to threshold_index\n",
    "    boxes_clustered = np.split(new_boxes, threshold_index + 1)\n",
    "    boxes_return = []\n",
    "    for cluster in boxes_clustered:\n",
    "        # sort according to x coordinate\n",
    "        cluster = cluster[cluster[:, 0].argsort()]\n",
    "        boxes_return.append(cluster)\n",
    "\n",
    "    return boxes_return\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"load model from path\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"load image from path\"\"\"\n",
    "    image = PIL.Image.open(image_path)\n",
    "    return image\n",
    "\n",
    "model_path = \"./yolov8m.pt\"\n",
    "\n",
    "try:\n",
    "    model = load_model(model_path)\n",
    "    model.overrides[\"conf\"] = 0.10  # NMS confidence threshold\n",
    "    model.overrides[\"iou\"] = 0.20  # NMS IoU threshold\n",
    "    model.overrides[\"agnostic_nms\"] = False  # NMS class-agnostic\n",
    "    model.overrides[\"max_det\"] = 1000  # maximum number of detections per image\n",
    "\n",
    "    image = load_image(\"./alpha-numeric.jpeg\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        res = model.predict(image, save=False, save_txt=False, exist_ok=True, conf=0.10)\n",
    "        boxes = res[0].boxes  # first image\n",
    "        res_plotted = res[0].plot()[:, :, ::-1]\n",
    "        list_boxes = parse_xywh_and_class(boxes)\n",
    "        str_predict = []\n",
    "        for box_line in list_boxes:\n",
    "            box_classes = box_line[:, -1]\n",
    "            for each_class in box_classes:\n",
    "                str_predict.append(model.names[int(each_class)])\n",
    "        print(str_predict)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # st.write(f\"Unable to load model. Check the specified path: {model_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b74737-7be7-490a-82e7-a58d7d9c28de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
